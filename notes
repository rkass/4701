The derivative of the input (used in adjusting weights), becomes NaN after input exceeds 709.
This is corrected by setting the derivative component to zero (the value assumed when input = 709) in this case.

The output is not fed through a transition function--to allow for the output to take on values in the
domain of the expected values. 

It seems like our hidden layers take on either 0 our 1 as their output values.

Possible directions and things to test:
  inputs, number and what they are
  hidden layers
  nodes/hidden layer
  ratio of training set to validation set
  loop on train and validate (gold digging)
